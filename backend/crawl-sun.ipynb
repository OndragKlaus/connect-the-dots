{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from pathlib import Path\n",
    "import json\n",
    "import requests\n",
    "from collections import namedtuple\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from secrets.config import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(url: str) -> str:\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.ok:\n",
    "            return response\n",
    "        else:\n",
    "            raise Exception('invalid response code', response)\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "\n",
    "apiKey = config[\"newsApiKey\"]\n",
    "        \n",
    "#print(\"https://newsapi.org/v1/articles?source=daily-mail&sortBy=top&apiKey={}\".format(apiKey))\n",
    "response = get_url(\"https://newsapi.org/v1/articles?source=daily-mail&sortBy=top&apiKey={}\".format(apiKey))\n",
    "j = response.json()\n",
    "articles = j[\"articles\"]\n",
    "print(len(j[\"articles\"]))\n",
    "print(articles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of objects with article id (count up with source+count), source_id, headline, excerpt, image_url, \n",
    "# article_url and full_text\n",
    "\n",
    "article = namedtuple(\"article\", [\"headline\", \"excerpt\", \"full_text\", \"image_url\", \"article_url\"])\n",
    "\n",
    "article_tuples = [article(a[\"title\"], a[\"description\"], \"\", a[\"urlToImage\"], a[\"url\"]) for a in articles]\n",
    "\n",
    "def get_article_text(a_url: str) -> str:\n",
    "    response = get_url(a_url)\n",
    "    data = response.content.decode('utf-8')\n",
    "    soup = BeautifulSoup(data, 'lxml')\n",
    "    text = \"\"\n",
    "    body = soup.find('div', {'itemprop': 'articleBody'})\n",
    "    if body is not None:\n",
    "        text = body.find_all('p', recursive=False)\n",
    "        text = [t.text for t in text]\n",
    "        return '\\n'.join(text)\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "# for each article get the text and add it to the array\n",
    "article_tuples_full = []\n",
    "for t in article_tuples:\n",
    "    text = get_article_text(t.article_url)\n",
    "    article_tuples_full.append(article(t.headline, t.excerpt, text, t.image_url, t.article_url))\n",
    "\n",
    "#print(article_tuples_full[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = Path('sql')\n",
    "path_data.mkdir(exist_ok=True)\n",
    "\n",
    "db_file = path_data / 'db.sqlite'\n",
    "create_tables_file = path_data / 'create_tables.sql'\n",
    "\n",
    "\n",
    "company_name = 'daily-mail'\n",
    "\n",
    "with sqlite3.connect(str(db_file)) as con:\n",
    "    cur = con.cursor()\n",
    "    cur.execute(\"select count(*) from company\")\n",
    "    print(cur.fetchone()[0])\n",
    "    cur.execute(\"select count(*) from article\")\n",
    "    print(cur.fetchone()[0])\n",
    "    \n",
    "    cur.execute(f'SELECT source_id from company WHERE name = ?', (company_name,))\n",
    "    x = cur.fetchone()\n",
    "    if x and len(x) > 0:\n",
    "        cur.execute(f'DELETE FROM article WHERE source_id = ?', (x[0],))\n",
    "        \n",
    "    cur.execute(f'DELETE FROM company WHERE name = ?', (company_name,))\n",
    "    cur.execute(f'INSERT INTO company (name) VALUES (?)', (company_name,))\n",
    "    cur.execute(f'SELECT source_id from company WHERE name = ?', (company_name,))\n",
    "    x = cur.fetchone()\n",
    "    if x and len(x) > 0:\n",
    "        company_id = x[0]\n",
    "    else:\n",
    "        raise Exception('?')\n",
    "    con.commit()\n",
    "        \n",
    "    cur.execute(\"select count(*) from article\")\n",
    "    print(cur.fetchone()[0])\n",
    "    #\"article\", [\"headline\", \"excerpt\", \"full_text\", \"image_url\", \"article_url\"]\n",
    "    for a in article_tuples_full:\n",
    "        cur.execute(f'INSERT INTO article (source_id, headline, excerpt, image_url, article_url, full_text) VALUES (?, ?, ?, ?, ?, ?)',\n",
    "                    (company_id, a.headline, a.excerpt, a.image_url, a.article_url, a.full_text))\n",
    "    con.commit()    \n",
    "    cur.execute(\"select count(*) from article\")\n",
    "    print(cur.fetchone()[0])\n",
    "    \n",
    "    cur.execute(\"select count(*) from company\")\n",
    "    print(cur.fetchone()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
