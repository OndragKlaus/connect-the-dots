{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "\n",
    "import requests\n",
    "from IPython.display import display, HTML\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(url: str) -> str:\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.ok:\n",
    "            return response.content.decode('utf-8')\n",
    "        else:\n",
    "            raise Exception('invalid response code', response)\n",
    "    except Exception as e:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_html = get_url('https://www.reuters.com/news/world')\n",
    "soup = BeautifulSoup(main_html, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = []\n",
    "\n",
    "articles = soup.find_all('div', {'class': 'moduleBody'})\n",
    "articles = [a for i, a in enumerate(articles) if i in [0, 1, 3]]\n",
    "articles = [sc.find_all(['h2', 'li']) for sc in articles]\n",
    "articles = [a.find('a')\n",
    "           for art in articles\n",
    "           for a in art]\n",
    "\n",
    "\n",
    "headlines = [a.text for a in articles]\n",
    "print(len(headlines))\n",
    "print(headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://www.reuters.com'\n",
    "article_urls = [base_url + a.get('href') for a in articles]\n",
    "article_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_image(url):\n",
    "    print('.', end='')\n",
    "#     print(url)\n",
    "    main_html = get_url(url)\n",
    "    soup = BeautifulSoup(main_html, 'lxml')\n",
    "    \n",
    "    image_url = 'http://horrowsports.ventures/wp-content/uploads/2016/01/Thomson-Reuters-logo.png'\n",
    "#     image_url = 'https://hackthevalley.thomsonreuters.com/assets/images/logo-reuters-kinesis-orange.svg'\n",
    "    container = soup.find('div', {'class': 'LazyImage_fallback_2kFne'})\n",
    "    if container is not None:\n",
    "        bg_image = container.get('style')\n",
    "        if len(bg_image) > 30:\n",
    "            image_url = 'https://' + bg_image[23:]\n",
    "            if '&w=' in image_url:\n",
    "                image_url = image_url[:image_url.index('&w=')]\n",
    "    \n",
    "    text = ''\n",
    "    excerpt = ''\n",
    "    body = soup.find('div', {'class': 'ArticleBody_body_2ECha'})\n",
    "    if body is not None:\n",
    "        text = body.find_all('p')\n",
    "        text = [t.text for t in text]\n",
    "        excerpt = text[0]\n",
    "        text = '\\n'.join(text)\n",
    "    return image_url, text, excerpt\n",
    "\n",
    "tmp = [extract_image(url) for url in article_urls]\n",
    "image_urls, texts, excerpts = list(zip(*tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excerpts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = Path('sql')\n",
    "path_data.mkdir(exist_ok=True)\n",
    "\n",
    "db_file = path_data / 'db.sqlite'\n",
    "create_tables_file = path_data / 'create_tables.sql'\n",
    "\n",
    "\n",
    "company_name = 'reuters'\n",
    "\n",
    "with sqlite3.connect(str(db_file)) as con:\n",
    "    cur = con.cursor()\n",
    "    cur.execute(\"select count(*) from company\")\n",
    "    print(cur.fetchone()[0])\n",
    "    cur.execute(\"select count(*) from article\")\n",
    "    print(cur.fetchone()[0])\n",
    "    \n",
    "    cur.execute(f'SELECT source_id from company WHERE name = ?', (company_name,))\n",
    "    x = cur.fetchone()\n",
    "    if x and len(x) > 0:\n",
    "        cur.execute(f'DELETE FROM article WHERE source_id = ?', (x[0],))\n",
    "        \n",
    "    cur.execute(f'DELETE FROM company WHERE name = ?', (company_name,))\n",
    "    cur.execute(f'INSERT INTO company (name) VALUES (?)', (company_name,))\n",
    "    cur.execute(f'SELECT source_id from company WHERE name = ?', (company_name,))\n",
    "    x = cur.fetchone()\n",
    "    if x and len(x) > 0:\n",
    "        company_id = x[0]\n",
    "    else:\n",
    "        raise Exception('?')\n",
    "    con.commit()\n",
    "        \n",
    "    cur.execute(\"select count(*) from article\")\n",
    "    print(cur.fetchone()[0])\n",
    "    for h, e, i, a, t in zip(headlines, excerpts, image_urls, article_urls, texts):\n",
    "        cur.execute(f'INSERT INTO article (source_id, headline, excerpt, image_url, article_url, full_text) VALUES (?, ?, ?, ?, ?, ?)',\n",
    "                    (company_id, h, e, i, a, t))\n",
    "    con.commit()    \n",
    "    cur.execute(\"select count(*) from article\")\n",
    "    print(cur.fetchone()[0])\n",
    "    \n",
    "    cur.execute(\"select count(*) from company\")\n",
    "    print(cur.fetchone()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
