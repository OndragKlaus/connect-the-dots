{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "\n",
    "import requests\n",
    "from IPython.display import display, HTML\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(url: str) -> str:\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.ok:\n",
    "            return response.content.decode('utf-8')\n",
    "        else:\n",
    "            raise Exception('invalid response code', response)\n",
    "    except Exception as e:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_html = get_url('http://www.dailymail.co.uk/news/worldnews/index.html')\n",
    "soup = BeautifulSoup(main_html, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = []\n",
    "\n",
    "articles = soup.find_all('div', {'class': 'article'})\n",
    "# articles = [a for i, a in enumerate(articles) if i in [0, 1, 3]]\n",
    "articles = [sc.find_all('h2') for sc in articles]\n",
    "articles = [a.find('a')\n",
    "           for art in articles\n",
    "           for a in art]\n",
    "\n",
    "\n",
    "headlines = [a.text for a in articles]\n",
    "print(len(headlines))\n",
    "print(headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'http://www.dailymail.co.uk'\n",
    "article_urls = [base_url + a.get('href') for a in articles]\n",
    "article_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def extract_image(url):\n",
    "    print('.', end='')\n",
    "#     print(url)\n",
    "    main_html = get_url(url)\n",
    "    soup = BeautifulSoup(main_html, 'lxml')\n",
    "    soup = soup.find('div', {'id': 'js-article-text'})\n",
    "    \n",
    "    image_url = 'http://i.dailymail.co.uk/i/pix/2016/04/06/02/0BFCB585000005DC-3525479-image-m-25_1459906645394.jpg'\n",
    "    img = soup.find('img')\n",
    "    if img is not None:\n",
    "        image_url = img.get('data-src', '')\n",
    "    \n",
    "    excerpt = ''\n",
    "    ul = soup.find('ul', {'class': 'mol-bullets-with-font'})\n",
    "    if ul is not None:\n",
    "        tmp = ul.find_all('li')\n",
    "        if tmp is not None:\n",
    "            tmp = [t.text for t in tmp]\n",
    "#             tmp = [t.find(['strong', 'b', 'p']) for t in tmp]\n",
    "#             if tmp is not None:\n",
    "#                 tmp = [t.text for t in tmp]\n",
    "            excerpt = ' '.join(tmp)\n",
    "    \n",
    "    text = ''\n",
    "    body = soup.find('div', {'itemprop': 'articleBody'})\n",
    "    if body is not None:\n",
    "        text = body.find_all('p', recursive=False)\n",
    "        text = [t.text for t in text]\n",
    "        text = '\\n'.join(text)\n",
    "    return image_url, text, excerpt\n",
    "\n",
    "# extract_image(article_urls[-5])\n",
    "tmp = [extract_image(url) for url in article_urls]\n",
    "image_urls, texts, excerpts = list(zip(*tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excerpts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = Path('sql')\n",
    "path_data.mkdir(exist_ok=True)\n",
    "\n",
    "db_file = path_data / 'db.sqlite'\n",
    "create_tables_file = path_data / 'create_tables.sql'\n",
    "\n",
    "\n",
    "company_name = 'dailymail'\n",
    "\n",
    "with sqlite3.connect(str(db_file)) as con:\n",
    "    cur = con.cursor()\n",
    "    cur.execute(\"select count(*) from company\")\n",
    "    print(cur.fetchone()[0])\n",
    "    cur.execute(\"select count(*) from article\")\n",
    "    print(cur.fetchone()[0])\n",
    "    \n",
    "    cur.execute(f'SELECT source_id from company WHERE name = ?', (company_name,))\n",
    "    x = cur.fetchone()\n",
    "    if x and len(x) > 0:\n",
    "        cur.execute(f'DELETE FROM article WHERE source_id = ?', (x[0],))\n",
    "        \n",
    "    cur.execute(f'DELETE FROM company WHERE name = ?', (company_name,))\n",
    "    cur.execute(f'INSERT INTO company (name) VALUES (?)', (company_name,))\n",
    "    cur.execute(f'SELECT source_id from company WHERE name = ?', (company_name,))\n",
    "    x = cur.fetchone()\n",
    "    if x and len(x) > 0:\n",
    "        company_id = x[0]\n",
    "    else:\n",
    "        raise Exception('?')\n",
    "    con.commit()\n",
    "        \n",
    "    cur.execute(\"select count(*) from article\")\n",
    "    print(cur.fetchone()[0])\n",
    "    for h, e, i, a, t in zip(headlines, excerpts, image_urls, article_urls, texts):\n",
    "        cur.execute(f'INSERT INTO article (source_id, headline, excerpt, image_url, article_url, full_text) VALUES (?, ?, ?, ?, ?, ?)',\n",
    "                    (company_id, h, e, i, a, t))\n",
    "    con.commit()    \n",
    "    cur.execute(\"select count(*) from article\")\n",
    "    print(cur.fetchone()[0])\n",
    "    \n",
    "    cur.execute(\"select count(*) from company\")\n",
    "    print(cur.fetchone()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
